#+STARTUP: indent
* 字体设置
现代版本的 Emacs 已经可以支持[[info:emacs#International][多国语言]]的字符集（Character sets）和字符编码
（encoding）。包括对含有非 ASCII 字符文件的访问、保存，在 Emacs 与其调用的程序间
传递非 ASCII 字符，显示非 ASCII 字符，插入、搜索等等。
** 与字体有关的基本概念
从根本上讲，目前的计算机底层只能处理 2 种信号，即高电平和低电平，惯例将之称为 1
和 0。通过显示设备呈现出来的所有信息，对计算机来说只是 1 和 0 的不同排列，我们所
看到的“字”也不例外。从计算机的角度看，可以根据使用者的设定，将二进制信息
=00110001= 理解和呈现为阿拉伯数字 =1= （即 ASCII 编码），也可将二进制信息=10000=
理解和呈现为阿拉伯数字 =1= （即莫尔斯电码，如果将短声作为 1 ，长声作为 0的话）。

为了便于互相交流，需要将二进制信息与一系列字符组成的集合（character set）之间的
对应关系统一起来，这种对应关系就是字符编码（character encoding）。最早最广泛使用
的字符编码就是 ASCII ，该编码用于英语环境，使用 7 位二进制表示，共 2^7=128 个字
符（其中 96 个是可打印的字符，包括大小写字母，数字和符号；32 个是控制符，不可打
印）。

很显然，ASCII 字符集因为仅包括了英语字母及符号，在其他语言环境中是不能满足需求的。
为了显示其他国家语言的字符集，就需要对 ASCII 字符编码进行扩充。相应的，各个国家
针对自己语言的字符集发展出了不同的字符编码，比如简体中文的 GB2312，繁体中文的
BIG5，日文的 JIS 等。

这种做法又回到了最初的问题上，某一大小为 2 字节的二进制信息在 GB2312 字符编码中
对应的字肯定与 BIG5 字符编码中对应的字不同。现在的问题是，不同国家之间（即使用不
同 2 字节字符编码系统）如何通过二进制信息进行交流。直白的说，在中国的计算机中采
用 GB2312 字符编码存储的一段二进制信息，复制到日本的计算机中使用 JIS 字符编码解
码出来完全变样了。

解决方法就是对字符编码再次扩充，使其能够每种语言中的每种字符设定统一且唯一的二进
制编码，目前这种编码就是 Unicode 编码。
** 知乎对字符编码的风趣解释
作者：匿名用户
链接：https://www.zhihu.com/question/19677619/answer/27516663
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

《ASCII、Unicode、GBK和UTF-8字符编码的区别联系》

很久很久以前，有一群人，他们决定用 8 个可以开合的晶体管来组合成不同的状态，以表
示世界上的万物。他们看到 8 个开关状态是好的，于是他们把这称为“字节”。再后来，
他们又做了一些可以处理这些字节的机器，机器开动了，可以用字节来组合出很多状态，状
态开始变来变去。他们看到这样是好的，于是它们就这机器称为“计算机”。

开始计算机只在美国用。八位的字节一共可以组合出 256 (2的8次方)种不同的状态。 他们
把其中的编号从 0 开始的 32 种状态分别规定了特殊的用途，一但终端、打印机遇上约定
好的这些字节被传过来时，就要做一些约定的动作。遇上 0x10, 终端就换行，遇上 0x07,
终端就向人们嘟嘟叫，例好遇上 0x1b, 打印机就打印反白的字，或者终端就用彩色显示字
母。他们看到这样很好，于是就把这些0x20以下的字节状态称为”控制码”。他们又把所有
的空格、标点符号、数字、大小写字母分别用连续的字节状态表示，一直编到了第 127 号，
这样计算机就可以用不同字节来存储英语的文字了。大家看到这样，都感觉很好，于是大家
都把这个方案叫做 ANSI 的“Ascii”编码（American Standard Code for Information
Interchange，美国信息互换标准代码）。当时世界上所有的计算机都用同样的ASCII方案来
保存英文文字。

后来，就像建造巴比伦塔一样，世界各地的都开始使用计算机，但是很多国家用的不是英文，
他们的字母里有许多是 ASCII 里没有的，为了可以在计算机保存他们的文字，他们决定采
用 127 号之后的空位来表示这些新的字母、符号，还加入了很多画表格时需要用下到的横
线、竖线、交叉等形状，一直把序号编到了最后一个状态 255。从 128 到 255 这一页的字
符集被称“扩展字符集”。从此之后，贪婪的人类再没有新的状态可以用了，美帝国主义可
能没有想到还有第三世界国家的人们也希望可以用到计算机吧！

等中国人们得到计算机时，已经没有可以利用的字节状态来表示汉字，况且有 6000 多个常
用汉字需要保存呢。但是这难不倒智慧的中国人民，我们不客气地把那些 127 号之后的奇
异符号们直接取消掉, 规定：一个小于 127 的字符的意义与原来相同，但两个大于 127 的
字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从 0xA1 用到
0xF7，后面一个字节（低字节）从 0xA1 到 0xFE，这样我们就可以组合出大约 7000 多个
简体汉字了。在这些编码里，我们还把数学符号、罗马希腊的字母、日文的假名们都编进去
了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就
是常说的“全角”字符，而原来在 127 号以下的那些就叫“半角”字符了。中国人民看到
这样很不错，于是就把这种汉字方案叫做 GB2312 。GB2312 是对 ASCII 的中文扩展。

但是中国的汉字太多了，我们很快就就发现有许多人的人名没有办法在这里打出来，特别是
某些很会麻烦别人的国家领导人。于是我们不得不继续把 GB2312 没有用到的码位找出来老
实不客气地用上。后来还是不够用，于是干脆不再要求低字节一定是127号之后的内码，只
要第一个字节是大于 127 就固定表示这是一个汉字的开始，不管后面跟的是不是扩展字符
集里的内容。结果扩展之后的编码方案被称为 GBK 标准，GBK 包括了 GB2312 的所有内容，
同时又增加了近 20000 个新的汉字（包括繁体字）和符号。后来少数民族也要用电脑了，
于是我们再扩展，又加了几千个新的少数民族的字，GBK 扩成了 GB18030。从此之后，中华
民族的文化就可以在计算机时代中传承了。中国的程序员们看到这一系列汉字编码的标准是
好的，于是通称他们叫做 “DBCS”（Double Byte Charecter Set 双字节字符集）。在
DBCS系列标准里，最大的特点是两字节长的汉字字符和一字节长的英文字符并存于同一套编
码方案里，因此他们写的程序为了支持中文处理，必须要注意字串里的每一个字节的值，如
果这个值是大于127的，那么就认为一个双字节字符集里的字符出现了。那时候凡是受过加
持，会编程的计算机僧侣们都要每天念下面这个咒语数百遍：“一个汉字算两个英文字符！
一个汉字算两个英文字符……”

因为当时各个国家都像中国这样搞出一套自己的编码标准，结果互相之间谁也不懂谁的编码，
谁也不支持别人的编码，连大陆和台湾这样只相隔了 150 海里，使用着同一种语言的兄弟
地区，也分别采用了不同的 DBCS 编码方案——当时的中国人想让电脑显示汉字，就必须装上
一个“汉字系统”，专门用来处理汉字的显示、输入的问题，但是那个台湾的愚昧封建人士
写的算命程序就必须加装另一套支持 BIG5 编码的什么“倚天汉字系统”才可以用，装错了
字符系统，显示就会乱了套！这怎么办？而且世界民族之林中还有那些一时用不上电脑的穷
苦人民，他们的文字又怎么办？真是计算机的巴比伦塔命题啊！

正在这时，大天使加百列及时出现了——一个叫 ISO（国际标谁化组织）的国际组织决定着手
解决这个问题。他们采用的方法很简单：废了所有的地区性编码方案，重新搞一个包括了地
球上所有文化、所有字母和符号的编码！他们打算叫它“Universal Multiple-Octet Coded
Character Set”，简称 UCS, 俗称 “unicode”。

unicode开始制订时，计算机的存储器容量极大地发展了，空间再也不成为问题了。于是
ISO 就直接规定必须用两个字节，也就是 16 位来统一表示所有的字符，对于 ASCII 里的
那些“半角”字符，unicode 保持其原编码不变，只是将其长度由原来的 8 位扩展为 16
位，而其他文化和语言的字符则全部重新统一编码。由于“半角”英文符号只需要用到低 8
位，所以其高 8 位永远是 0，因此这种大气的方案在保存英文文本时会多浪费一倍的空间。

这时候，从旧社会里走过来的程序员开始发现一个奇怪的现象：他们的 strlen 函数靠不住
了，一个汉字不再是相当于两个字符了，而是一个！是的，从 unicode 开始，无论是半角
的英文字母，还是全角的汉字，它们都是统一的“一个字符”！同时，也都是统一的“两个
字节”，请注意“字符”和“字节”两个术语的不同，“字节”是一个 8 位的物理存贮单
元，而“字符”则是一个文化相关的符号。在 unicode 中，一个字符就是两个字节。一个
汉字算两个英文字符的时代已经快过去了。

unicode 同样也不完美，这里就有两个的问题，一个是，如何才能区别 unicode 和 ascii
？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？第二个问题是，我
们已经知道，英文字母只用一个字节表示就够了，如果 unicode 统一规定，每个符号用三
个或四个字节表示，那么每个英文字母前都必然有二到三个字节是 0，这对于存储空间来说
是极大的浪费，文本文件的大小会因此大出二三倍，这是难以接受的。

unicode 在很长一段时间内无法推广，直到互联网的出现，为解决 unicode 如何在网络上
传输的问题，于是面向传输的众多 UTF（UCS Transfer Format）标准出现了，顾名思义，
UTF-8 就是每次 8 个位传输数据，而 UTF-16 就是每次 16 个位。UTF-8 就是在互联网上
使用最广的一种 unicode的实现方式，这是为传输而设计的编码，并使编码无国界，这样就
可以显示全世界上所有文化的字符了。

UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用 1~4 个字节表示一个符
号，根据不同的符号而变化字节长度，当字符在 ASCII 码的范围时，就用一个字节表示，
保留了 ASCII 字符一个字节的编码做为它的一部分，注意的是 unicode 一个中文字符占 2
个字节，而 UTF-8 一个中文字符占 3 个字节）。从 unicode 到 uft-8 并不是直接的对应，
而是要过一些算法和规则来转换。

| Unicode符号范围     | UTF-8编码方式                       |
| (十六进制)          | （二进制）                          |
|---------------------+-------------------------------------|
| 0000 0000-0000 007F | 0xxxxxxx                            |
| 0000 0080-0000 07FF | 110xxxxx 10xxxxxx                   |
| 0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx          |
| 0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx |

** 常见的中文字符编码
*** GB2312
GB2312 是中国国家标准的简体中文字符集，又称为 GB2312-80 字符集，全称为《信息交换
用汉字编码字符集·基本集》，由原中国国家标准总局发布，1981 年 5 月 1 日实施。它收
录简化汉字及一般符号、序号、数字、拉丁字母、日文假名、希腊字母、俄文字母、汉语拼
音符号、汉语注音字母，共 7445 个图形字符。其中包括6763个汉字（其中一级汉字3755个，
二级汉字3008个）以及包括拉丁字母、希腊字母、日文平假名及片假名字母、俄语西里尔字
母在内的682个全角字符。其收录的汉字已经覆盖99.75%的使用频率，基本满足了汉字的计
算机处理需要。
*** BIG5
又称大五码或五大码，1984年由台湾财团法人信息工业策进会和五家软件公司宏碁 (Acer)、
神通 (MiTAC)、佳佳、零壹 (Zero One)、大众 (FIC)创立，故称大五码。Big5 码的产生源
于当时台湾不同厂商各自推出不同的编码（如倚天码、IBM PS55、王安码等）彼此不能兼容，
而且，台湾政府当时也推出官方的汉字编码，同时，中国大陆当时的 GB2312 编码又没有收
录繁体中文字。Big5 字符集共收录 13053 个中文字，耐人寻味的是该字符集中的两个字符
各有两个不同的编码：“兀”(0xA461及0xC94A)、“嗀”(0xDCD1及0xDDFC)。
*** GB18030
GB18030 的全称是 GB18030-2000《信息交换用汉字编码字符集基本集的扩充》，是中国政
府于 2000 年 3 月 17 日发布的新的汉字编码国家标准，2001 年 8 月 31 日后在中国市
场上发布的软件必须符合本标准。该字符集收录了 27484 个汉字，覆盖中文、日文、朝鲜
语和中国少数民族文字，满足中国大陆、香港、台湾、日本和韩国等东亚地区信息交换多文
种、大字量、多用途、统一编码格式的要求，与 GB2312 字符集的字符编码兼容。同时填补
了 Unicode 扩展字符字汇“统一汉字扩展A”的内容，与 Unicode 3.0 版本兼容。

** Unicode 字符编码
- script
- fontset
** Emacs 字体机制
Emacs 内部使用其自有的多字节字符（multibyte character）编码，是基于 Unicode 标准
的一个超集。该编码可以实现 buffer 或字符串由来自不同 script 的字符混合组成。在读
写文件、传递数据时，Emacs 会在内部编码与实际编码之间进行转换。

只要 Emacs 启用了多字节字符功能，其所支持的所有字符集就可以被支持。没有必要为了
显示某种语言的字符而特地选择该语言。但为了让 Emacs 默认的字体处理方式更符合使用
者的要求，选择日常使用的语言环境（language environment）仍然很重要。设置语言环节
的目的在于选择更偏好的 script 而不是选择某种语言。

Emacs 中，script 与字符之间的对应关系由变量 =script-representative-char= 定义。

为了显示语言环境所用的 script，需要设置合适的字体。

- =locale-preferred-coding-systems= :: list of pairs of =locale regexps= and
     =preferred coding systems= .

Emacs 引入 Fontset 概念，与 charater set 相比，顾名思义，就是字体的集合，即一系
列字体组合在一起。通过命令 =describe-fontset= 可以查看 Emacs 在运行时所使用的
Fontset。其中，Emacs 自动创建 3 个 Fontset 为：
- fontset-startup :: 
- fontset-standard ::
- fontset-default :: 

在 25.2 版本中 Emacs 引入了变量 =use-default-font-for-symbols= ，默认值为 =t= 。
如果不将其设为 =nil= ，Emacs 将无视看起来更具优先级的字体设置，并始终用默认的字
体显示 =symbol= 这类 script 的字符。比如默认字体为 =Source Code Pro= 的情况下，
即便显式地设置 =symbol= 的字符 =◉= 使用 =DejaVu Sans Mono= 字体显示，仍然无效。

以上字符尽管没有使用想要的字体显示，但在等宽字体中显示的宽度仍然为 1 ，在 Org 的
表格中尚能对齐。而某些中文标点如 =“= 的 =preferred charset= 为 =chinese-gbk= ，
Emacs 默认齐宽度为 2 ，如果仍然使用默认的字体（大多数时候为英文字体）显示，则在
Org 中无法实现对齐。
#+BEGIN_SRC emacs-lisp
(set-fontset-font t "#x201c" "Microsoft Yahei" nil 'prepend) ; “
(set-fontset-font t "#x24c9" "DejaVu Sans Mono" nil 'prepend) ;  ◉
#+END_SRC

如果希望在 Emacs 中上述用于显示 =symbol= 类字符的显式设置能够生效，必须：
#+BEGIN_SRC emacs-lisp
(setq use-default-font-for-symbols nil)
#+END_SRC

以上设置后，为使 =symbol= 类的 script 字符尽可能地正常显示，最好不要直接针对该
script 设置字体。如有需要，应单独对属于 =symbol= 类的特定字符设置字体。

还有一些字符（如 =×= ）在 Emacs 中的 preferred charset 为 chinese-gbk ，但实际
被识别为 latin 且 codepoint 为 #xd7 。由于 Emacs 认为其是 CJK 字符，所以宽度算作
2 ，但实际显示的宽度为 1 ，也会导致 Org 表格的对齐问题。针对这一类，可以修改
Emacs 的宽度识别：
#+BEGIN_SRC emacs-lisp
  (defconst xx-chars-width-should-be-1 "×±÷")

  (defun xx//set-char-width-to-1 (alist)
    (while (char-table-parent char-width-table)
      (setq char-width-table (char-table-parent char-width-table)))
    (dolist (pair alist)
      (let ((width (car pair))
            (chars (cdr pair))
            (table (make-char-table nil)))
        (dolist (char chars)
          (set-char-table-range table char width))
        (optimize-char-table table)
        (set-char-table-parent table char-width-table)
        (setq char-width-table table))))

  (char-width (string-to-char "×"))

  (blaenk/set-char-widths
   `((1 . (,(string-to-char "“")
           ,(string-to-char "”")
           ,(string-to-char "…")
           ))))
#+END_SRC

*** brep@emacs.newsmth 关于 Emacs23 版本编码的综述
http://www.newsmth.net/bbscon.php?bid=573&id=44992

 Emacs 的编码系统这个话题太大了，得写一篇很长的文章才能说清楚。而且对于用户来说，
可能并不感兴趣，也不关心这个。

Emacs22 的编码原理是让多个国家的编码系统共存。buffer里的每一个字符都用 1－4 个字
节表示，比如 gb2312 的汉字就是用3个字节表示，这三个字节中的第一个字节叫 leading
byte, 说明了这个字符所属的字符集，后面两个字节是这个字符的gb2312编码。
chinese-gb2312 的 leading byte是 0x91, big5 因为比较大，所以分成了两个 charset:
chinese-big5-1和 chinese-big5-2, leading byte 分别是 0x98 和 0x99。

所以对于 Emacs22 来说，只要查看一个字符的 leading byte，就可以知道它属于哪个字符
集，一看是 0x91 就知道它是 gb2312 字符，一看是 0x98就知道它是 big5 字符。所以一
个汉字可能会有好几种内部编码，比如“好”字，gb2312, big5, 朝鲜文, 日文中都有这个
字，那么它就有四种内部编码。

当 Emacs22 打开一个文件的时候，就需要判断出这个文件的编码系统，然后给文件中的每
个字符加上 leading byte，放到内存中，Emacs22把这个过程叫做 decode。当emacs22保存
文件时就需要根据每个字符的 leading byte 把它转换成相应字符集的编码，再写到文件中，
emacs22把这个过程叫做 encode。

为了演示 Emacs decode/encode 的过程，我们可以做个小实验：

  - 新建一个文件 ~/test.txt
  - 输入“中文”两个字
  - C-x <return> f gb2312
  - C-x C-s 保存文件
  - 在 *scrach* buffer 里输入
    (insert-file-contents-literally "~/test.txt")
    C-j 一下可以看到 \326\320\316\304 ，这是八进制的“中文”两个字的编码。
  - 现在打开 ~/test.txt，然后执行
    M-x toggle-enable-multibyte-characters
    我们可以看到 \221\326\320\221\316\304，Emacs在每个汉字的编码前都加
    上了一个 \221，正是十六进制的 0x91——gb2312的 leading byte。

然而，leading byte 的数量是有限的，而世界上的字符集却越来越多，因此当 gbk 和
gb18030 出现以后，就没有合适的 leading byte 分配给它们，所以 Emacs22 不支持 gbk
和 gb18030。

苏勇和詹剑写的 mule-gbk，实际上是把全部的gbk字符分成了三部分，分别占用了
chinese-cns-5, chinese-cns-6, chinese-cns-7 的 3 个leading byte。mule-gbk 的主要
代码就是把 gbk 中的字符加上这三个leading byte 之一，放入内存，也就是 decode；或
者反过来把内存中带有这三个 leading byte 之一的字符转换成 gbk 编码，也就是 encode。
Emacs为了方便进行各种编码的转换，专门内嵌了一种称为 ccl 的语言，编码转换部分的代
码就是用 ccl 写成的。

Emacs23 的编码原理是把所有的字符集都转换成 utf-8，内部字符都是 utf-8 编码。这样
对于每个字符集都需要两张表，一个是 charset --> utf-8，另一个是 utf-8 --> charset。
Emacs23 源码的 etc/charsets/ 目录下有很多 *.map 文件，就是这种转换表。

当 Emacs23 打开一个文件时，先判断文件的编码，然后加载相应的表格，再按照表格把文
件中的字符一个一个转换成 utf-8 放入内存；保存文件时，也是按照表格把内部的 utf-8
编码转换成相应的字符集编码。

unicode 的全部编码可以分成很多 block，在 www.unicode.org 可以查到。由于中国参与
unicode 的制定比较晚，因此造成了gb2312/gbk/gb18030中的字符被分配到了很多不同的
block 中，汉字还相对比较连续，标点符号就特别分散，这个block中有几个，那个block中
有几个。

Emacs 23 在进行 fill 时不整齐的原因，主要是那些标点符号的宽度属性设置错误，本来
应该是2，却设成了1，因此 fill 时计算行宽不准确，标点符号越多，误差越大。我的那个
patch主要是更改了这些标点符号的宽度属性。
#+BEGIN_SRC emacs-lisp
  (let ((l '(chinese-gb2312
              gb18030-2-byte
   gb18030-4-byte-bmp
              gb18030-4-byte-ext-1
   gb18030-4-byte-ext-2
              gb18030-4-byte-smp)))
     (dolist (elt l)
       (map-charset-chars #'modify-category-entry elt ?|)
   (map-charset-chars
        (lambda (range ignore)
   (set-char-table-range char-width-table range 2))
   elt)))
#+END_SRC
** Spacemacs 字体机制
*** 默认字体设置
=core-fonts-support.el= 定义的函数 =spacemacs/set-default-font= 会在变量
=default-frame-alist= 中加入字体的设置。如果不采用 Spacemacs 的字体设置机制，而
希望自己另行设置，应该需要将该设置从 =default-frame-alist= 变量中移除，然后添加
自己的设置。
#+BEGIN_SRC emacs-lisp
  (assq-delete-all 'font default-frame-alist)
  ;; (set-frame-font fontspec nil t)
  (push `(font . ,(frame-parameter nil 'font)) default-frame-alist)
#+END_SRC

*** modeline 的高度（powerline）
spacemacs 使用 powerline 增强原生的 modeline，并引入变量 =powerline-scale= 并通
过函数 =spacemacs/compute-powerline-height= 辅助计算 powerline 中的变量
=powerline-height= ，powerline 根据该变量调整 =separator-height= 的值，最后需要
调用 *powerline-reset* 重新绘制相关图案。
** CJK 的特性及处理
现代版本的 Emacs 已经可以正常的显示 CJK 字符了，但是 CJK 字符与 ASCII 字符之间存
在一些不同的特性，比如中文字体字形的尺寸与英文字体不同，导致显示时不能很好地对齐
等问题。通过对 Emacs 字体机制的适当调整，可以满足部分要求。
*** 中英文字符的等宽显示
中英文字形尺寸上的区别，导致中英文同时出现时不能做到即等宽又等高，Emacs 会默认使
用同样大小的中英文字体，因此中英文字体默认是等高的。这种默认设置在某些场景中，如
minibuffer 或 modeline 中是完全能够接收的。但在另外的某些场景中，如 org-mode 的
表格竖线对齐在视觉上更清爽，但 org-mode 的自动对齐功能是通过计算字符的宽度来实现
的，因此等宽的需求会高于等高。为实现等宽，需要对中英文字体分别设置大小
